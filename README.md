# ğŸ¤– ft_linear_regression

## ğŸ“‹ Description
ImplÃ©mentation complÃ¨te d'une **rÃ©gression linÃ©aire from scratch** en Python, dÃ©veloppÃ©e dans le cadre du cursus **Ã‰cole 42**.

Ce projet dÃ©montre la comprÃ©hension des algorithmes de Machine Learning fondamentaux sans utiliser de bibliothÃ¨ques spÃ©cialisÃ©es comme scikit-learn.

## ğŸ¯ Objectifs
- ImplÃ©menter l'algorithme de **descente de gradient**
- PrÃ©dire le prix d'une voiture en fonction du kilomÃ©trage
- MaÃ®triser la **normalisation des donnÃ©es**
- CrÃ©er une architecture modulaire avec 2 programmes distincts

## ğŸ› ï¸ Technologies utilisÃ©es
![Python](https://img.shields.io/badge/-Python-3776AB?style=flat&logo=python&logoColor=white)
![Matplotlib](https://img.shields.io/badge/-Matplotlib-11557c?style=flat)
![NumPy](https://img.shields.io/badge/-Math-013243?style=flat)

## ğŸ“ Structure du projet
```
ft_linear_regression/
â”œâ”€â”€ ğŸ“„ README.md           # Documentation
â”œâ”€â”€ ğŸ train.py           # Programme d'entraÃ®nement
â”œâ”€â”€ ğŸ predict.py         # Programme de prÃ©diction
â”œâ”€â”€ ğŸ“Š data.csv           # Dataset (kilomÃ©trage, prix)
â”œâ”€â”€ ğŸ“ˆ theta.csv          # ParamÃ¨tres sauvegardÃ©s
â””â”€â”€ ğŸ–¼ï¸ regression_graphique.png  # Visualisation
```

## ğŸš€ Installation & Utilisation

### PrÃ©requis
```bash
# Installation de matplotlib (optionnel pour la visualisation)
pip install matplotlib
```

### EntraÃ®nement du modÃ¨le
```bash
python3 train.py
```
**Sortie attendue :**
- Affichage du progrÃ¨s d'entraÃ®nement
- GÃ©nÃ©ration du graphique de rÃ©gression
- Sauvegarde des paramÃ¨tres Î¸0 et Î¸1
- Tests de prÃ©diction automatiques

### PrÃ©diction de prix
```bash
python3 predict.py
```
**Utilisation :**
1. Saisissez le kilomÃ©trage souhaitÃ©
2. Le programme affiche le prix estimÃ©
3. RÃ©pÃ©tez ou quittez

## ğŸ“Š Algorithme implÃ©mentÃ©

### Formule de prÃ©diction
```
Prix estimÃ© = Î¸0 + (Î¸1 Ã— kilomÃ©trage)
```

### Descente de gradient
```python
# Calcul des gradients
gradient_Î¸0 = (1/m) Ã— Î£(prÃ©diction - prix_rÃ©el)
gradient_Î¸1 = (1/m) Ã— Î£((prÃ©diction - prix_rÃ©el) Ã— kilomÃ©trage)

# Mise Ã  jour des paramÃ¨tres
Î¸0 = Î¸0 - learning_rate Ã— gradient_Î¸0
Î¸1 = Î¸1 - learning_rate Ã— gradient_Î¸1
```

### Normalisation Z-score
```python
valeur_normalisÃ©e = (valeur - moyenne) / Ã©cart_type
```

## ğŸ“ˆ Exemple de rÃ©sultats

```bash
=== TESTS DE PRÃ‰DICTION ===
50,000 km â†’ 7,427.15â‚¬
100,000 km â†’ 6,354.70â‚¬
150,000 km â†’ 5,282.26â‚¬
200,000 km â†’ 4,209.81â‚¬
```

## ğŸ¨ Visualisation
Le programme gÃ©nÃ¨re automatiquement un graphique montrant :
- Points de donnÃ©es rÃ©els (scatter plot)
- Droite de rÃ©gression linÃ©aire
- Ã‰quation de la rÃ©gression

## âš™ï¸ ParamÃ¨tres techniques
- **Learning rate** : 0.01 (ajustable)
- **Ã‰poques** : 2000 iterations
- **Normalisation** : Z-score complÃ¨te
- **Algorithme** : Gradient Descent Batch

## ğŸ§  CompÃ©tences dÃ©montrÃ©es
- **Machine Learning** : RÃ©gression linÃ©aire, descente de gradient
- **MathÃ©matiques** : Statistiques, optimisation
- **Python** : Programmation orientÃ©e fonctions, gestion de fichiers
- **Data Science** : Normalisation, visualisation
- **Architecture logicielle** : ModularitÃ©, sÃ©paration des responsabilitÃ©s

## ğŸ“š Concepts abordÃ©s
- âœ… Algorithmes d'apprentissage supervisÃ©
- âœ… Fonction de coÃ»t (Mean Squared Error)
- âœ… Optimisation par gradient descent
- âœ… Preprocessing des donnÃ©es
- âœ… Validation de modÃ¨les

## ğŸ“ Contexte acadÃ©mique
**Ã‰cole 42** - Projet ft_linear_regression  
**Section** : Intelligence Artificielle  
**Objectif** : Comprendre les fondements du Machine Learning

## ğŸ“ Notes d'implÃ©mentation
- Pas d'utilisation de bibliothÃ¨ques ML (scikit-learn, etc.)
- Code from scratch pour une comprÃ©hension approfondie
- Gestion robuste des erreurs et edge cases
- Interface utilisateur claire et informative

---
*DÃ©veloppÃ© avec passion pour l'IA et l'apprentissage automatique* ğŸš€
